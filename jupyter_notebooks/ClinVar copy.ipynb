{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import pandas as pd
import json

####################################################
# 1. Extend the model with a masking head (LM Head)
####################################################
class ESMCMasked(nn.Module):
    """
    A simple wrapper that takes a pre-trained ESM C model and adds
    a masking (language modeling) head on top of the final hidden states.
    """
    def __init__(self, base_model, hidden_dim=64, num_aa=33):
        super().__init__()
        self.base_model = base_model  # Pretrained ESM C model
        self.mask_head = nn.Linear(hidden_dim, num_aa)  # Simple linear LM head

    def forward(self, protein_obj, mask_positions=None):
        # Encode the protein to get initial embeddings
        encoded_seq = self.base_model.encode(protein_obj)
        # Obtain the hidden representations (logits call ensures forward pass)
        logits_out = self.base_model.logits(
            encoded_seq,
            LogitsConfig(sequence=True, return_embeddings=False)
        )
        # logits_out.logits.sequence is a list of length batch_size; here presumably 1
        # hidden has shape [L, hidden_dim] if single-sequence
        hidden = logits_out.logits.sequence[0]

        # Convert hidden from bfloat16 to float32 (match linear layer weights)
        hidden = hidden.to(self.mask_head.weight.dtype)

        # Pass through the custom LM head
        out_logits = self.mask_head(hidden)  # shape: [L, num_aa]

        if mask_positions is not None:
            # Return just the masked positions
            masked_logits = out_logits[mask_positions]
            return masked_logits, hidden
        else:
            # Or return logits for every position
            return out_logits

def load_finetuned_model(model_path, full_pretraining=False, device='cuda'):
    # Load checkpoint
    checkpoint = torch.load(model_path, map_location=device)
    config = checkpoint['config']
    
    # 1. Load base ESMC model
    base_model = ESMC.from_pretrained("esmc_300m").to(device)
    
    # 3. Wrap with ESMCMasked using saved config
    model = ESMCMasked(
        base_model,
        hidden_dim=config['hidden_dim'],
        num_aa=config['num_aa']
    ).to(device)
    
    # 4. Load trained weights
    model.load_state_dict(checkpoint['model_state_dict'])
    
    return model

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
 ename": "KeyboardInterrupt",
 evalue": "",
 output_type": "error",
 traceback": [
  \u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
  \u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
  Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mesm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ESMProtein, LogitsConfig\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_finetuned_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m"\u001b[39;49m\u001b[38;5;124;43m/global/scratch/users/sergiomar10/models/esm_c/masking/fine_tuned/False-Full_pretraining_20000_seq_2.pt\u001b[39;49m\u001b[38;5;124;43m"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_pretraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Must match training setting!\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set to evaluation mode\u001b[39;00m
  Cell \u001b[0;32mIn[1], line 49\u001b[0m, in \u001b[0;36mload_finetuned_model\u001b[0;34m(model_path, full_pretraining, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_finetuned_model\u001b[39m(model_path, full_pretraining\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     config \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# 1. Load base ESMC model\u001b[39;00m
  File \u001b[0;32m/clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/torch/serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m
  File \u001b[0;32m/clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/torch/serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()
  File \u001b[0;32m/clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/torch/_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m"\u001b[39m\n\u001b[1;32m    508\u001b[0m     ):\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[1;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m"\u001b[39m\n\u001b[1;32m    511\u001b[0m         )\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]
  File \u001b[0;32m/clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/torch/serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage
  File \u001b[0;32m/clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/torch/serialization.py:1888\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1885\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset : storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     storage \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1888\u001b[0m         \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1889\u001b[0m         \u001b[38;5;241m.\u001b[39m_typed_storage()\n\u001b[1;32m   1890\u001b[0m         \u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1891\u001b[0m     )\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:
  \u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
from esm.models.esmc import ESMC
from esm.sdk.api import ESMProtein, LogitsConfig

model = load_finetuned_model(
    "/global/scratch/users/sergiomar10/models/esm_c/masking/fine_tuned/False-Full_pretraining_20000_seq_2.pt",
    full_pretraining=False,  # Must match training setting!
    device=device
)
model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
import pandas as pd
import pysam
from Bio.Seq import Seq
import re

# Define file paths
gtf_path = "/global/scratch/users/sergiomar10/data/GCF_000001405.40_GRCh38.p14_genomic.gtf"
vcf_path = "/global/scratch/users/sergiomar10/data/clinvar_20210302.vcf.gz"
fasta_path = "/global/scratch/users/sergiomar10/data/GCF_000001405.40_GRCh38.p14_genomic.fna"

# -----------------------------------------------------
# 1. Load and parse the GTF file with pandas
gtf_cols = ["chrom", "source", "feature", "start", "end", "score", "strand", "frame", "attributes"]
gtf_df = pd.read_csv(gtf_path, sep="\\t", comment='#', header=None, names=gtf_cols)

# Keep only CDS features
cds_df = gtf_df[gtf_df['feature'] == 'CDS'].copy()

# Function to extract transcript_id from the attributes column
def extract_transcript_id(attr):
    match = re.search('transcript_id "([^"]+)"', attr)
    if match:
        return match.group(1)
    return None

cds_df['transcript_id'] = cds_df['attributes'].apply(extract_transcript_id)

# Group CDS features by transcript
# We build a dictionary: transcript_id -> list of exons (each as a dict with chrom, start, end, strand)
cds_by_transcript = {}
for transcript, group in cds_df.groupby("transcript_id"):
    # Use the strand from the first row (assumed consistent across exons)
    strand = group.iloc[0]['strand']
    # For plus strand, sort exons by start; for minus, sort in reverse genomic order
    if strand == "+":
        group_sorted = group.sort_values("start")
    else:
        group_sorted = group.sort_values("start", ascending=False)
    exons = []
    for _, row in group_sorted.iterrows():
        exon = {
            "chrom": row["chrom"],
            "start": int(row["start"]),
            "end": int(row["end"]),
            "strand": row["strand"]
        }
        exons.append(exon)
    cds_by_transcript[transcript] = exons

# -----------------------------------------------------
# 2. Helper functions to rebuild the CDS sequence and find overlapping transcripts

def get_transcript_cds_with_mapping(transcript_id, exons, fasta):
    """
    Given a transcript's exons (list of dicts with chrom, start, end, strand)
    and an open pysam FASTA file, return:
      - full CDS sequence as a string,
      - a mapping list where each CDS index maps to (chrom, genomic_position),
      - the strand.
    """
    strand = exons[0]["strand"]
    cds_seq = ""
    mapping = []
    for exon in exons:
        chrom = exon["chrom"]
        start = exon["start"]
        end = exon["end"]
        # pysam FASTA is 0-based so subtract 1 from start
        seq = fasta.fetch(chrom, start - 1, end)
        if strand == "-":
            # For the minus strand, reverse complement the exon sequence
            seq = str(Seq(seq).reverse_complement())
            # Build mapping in reverse order
            positions = [(chrom, pos) for pos in range(end, start - 1, -1)]
        else:
            positions = [(chrom, pos) for pos in range(start, end + 1)]
        cds_seq += seq
        mapping.extend(positions)
    return cds_seq, mapping, strand

def get_transcripts_overlapping_variant(chrom, pos, cds_by_transcript):
    """
    Return a list of transcript IDs where the variant (chrom, pos) falls within at least one CDS exon.
    """
    overlapping = []
    for transcript, exons in cds_by_transcript.items():
        for exon in exons:
            if exon["chrom"] == chrom and exon["start"] <= pos <= exon["end"]:
                overlapping.append(transcript)
                break  # if one exon overlaps, no need to check further for this transcript
    return overlapping

# -----------------------------------------------------
# 3. Open FASTA and VCF files using pysam
fasta = pysam.FastaFile(fasta_path)
vcf = pysam.VariantFile(vcf_path)

records = []
variant_count = 0  # To count the number of processed variants

# Map from common numeric/letter chromosome IDs (as found in VCF) 
# to the full NCBI contig names in the FASTA
chrom_map = {
    "1":  "NC_000001.11",
    "2":  "NC_000002.12",
    "3":  "NC_000003.12",
    "4":  "NC_000004.12",
    "5":  "NC_000005.10",
    "6":  "NC_000006.12",
    "7":  "NC_000007.14",
    "8":  "NC_000008.11",
    "9":  "NC_000009.12",
    "10": "NC_000010.11",
    "11": "NC_000011.10",
    "12": "NC_000012.12",
    "13": "NC_000013.11",
    "14": "NC_000014.9",
    "15": "NC_000015.10",
    "16": "NC_000016.10",
    "17": "NC_000017.11",
    "18": "NC_000018.10",
    "19": "NC_000019.10",
    "20": "NC_000020.11",
    "21": "NC_000021.9",
    "22": "NC_000022.11",
    "X":  "NC_000023.11",
    "Y":  "NC_000024.10",
    "MT": "NC_012920.1",  # Mitochondrial DNA
}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
 name": "stderr",
 output_type": "stream",
 text": [
  /clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/Bio/Seq.py:2879: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.
    warnings.warn(\n"
     ]
    },
    {
 name": "stdout",
 output_type": "stream",
 text": [
  Processed 97 variants
  Recorded 551 coding variants with relevant clinical significance.\n"
     ]
    }
   ],
   "source": [
variant_count = 0  # To count the number of processed variants
records = []

for x, rec in enumerate(vcf.fetch()):
    # Filter based on clinical significance: only process variants that are Pathogenic or Benign.
    # (Assumes that the 'CLNSIG' field is present and contains strings like "Pathogenic" or "Benign")
    clnsig = rec.info.get('CLNSIG')
    if clnsig is None or not any(sig in {"Pathogenic", "Benign"} for sig in clnsig):
        continue

    # print(rec.chrom, rec.pos, rec.ref, rec.alts, clnsig)

    chrom = rec.chrom
    pos  = rec.pos
    ref = rec.ref
    alts = rec.alts

    # Map chromosome names if needed
    if chrom in chrom_map:
        chrom = chrom_map[chrom]
    
    transcripts = get_transcripts_overlapping_variant(chrom, pos, cds_by_transcript)

    if not transcripts:
        continue  # Skip non-coding variants

    # Process each overlapping transcript
    for transcript in transcripts:
        exons = cds_by_transcript[transcript]
        cds_seq, mapping, strand = get_transcript_cds_with_mapping(transcript, exons, fasta)
        
        # Confirm the variant's genomic coordinate is part of the CDS mapping
        if (chrom, pos) not in mapping:
            continue

        cds_index = mapping.index((chrom, pos))
        
        # Construct the mutated CDS sequence.
        # Note: This example assumes a simple SNP (i.e. ref and alt of length 1).
        mutated_seq = cds_seq[:cds_index] + rec.alts[0] + cds_seq[cds_index + 1:]
        
        # Translate the CDS sequences into proteins.
        ref_protein = str(Seq(cds_seq).translate(to_stop=False))
        mut_protein = str(Seq(mutated_seq).translate(to_stop=False))

        if len(mut_protein) < 10:
            break
        
        residue_index = cds_index // 3


        record = {
            "chrom": chrom,
            "pos": pos,
            "transcript": transcript,
            "mutated_residue": residue_index,
            "cds_index": cds_index,
            "cds_seq": ref_protein,
            "mutated_seq": mut_protein,
            "strand": strand,
            "clnsig": clnsig,
        }
        records.append(record)

    variant_count += 1

    if x > 1000:
        break

print("Processed", variant_count, "variants")
print("Recorded", len(records), "coding variants with relevant clinical significance.")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
variants_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
 name": "stdout",
 output_type": "stream",
 text": [
  aa_to_idx: {'A': 5, 'R': 10, 'N': 17, 'D': 13, 'C': 23, 'E': 9, 'Q': 16, 'G': 6, 'H': 21, 'I': 12, 'L': 4, 'K': 15, 'M': 20, 'F': 18, 'P': 14, 'S': 8, 'T': 11, 'W': 22, 'Y': 19, 'V': 7}
  idx_to_aa: {5: 'A', 10: 'R', 17: 'N', 13: 'D', 23: 'C', 9: 'E', 16: 'Q', 6: 'G', 21: 'H', 12: 'I', 4: 'L', 15: 'K', 20: 'M', 18: 'F', 14: 'P', 8: 'S', 11: 'T', 22: 'W', 19: 'Y', 7: 'V'}\n"
     ]
    }
   ],
   "source": [
#########################################################
# 4. Define a mapping for the 20 standard amino acids
#########################################################
amino_acids = "ARNDCEQGHILKMFPSTWYV"

# Map each amino acid to its tokenizer-assigned ID
aa_to_idx = {
    aa: model.base_model.tokenizer(text=aa).input_ids[1]  # index=1 to skip <cls> or start token
    for aa in amino_acids
}

# Reverse mapping: token_id → amino acid
idx_to_aa = {idx: aa for aa, idx in aa_to_idx.items()}

print(f"aa_to_idx: {aa_to_idx}", flush=True)
print(f"idx_to_aa: {idx_to_aa}", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
from esm.sdk.api import ESMProtein, LogitsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
results = []

# Loop over each variant record (each protein sequence)
for idx, row in variants_df.iterrows():
    # Get the protein sequence from the record. (Here we use the mutated sequence.)
    protein_seq = row['mutated_seq']
    protein = ESMProtein(sequence=protein_seq)
    
    # -------------------------------
    # 1. Encode the protein and determine valid positions
    # -------------------------------
    # Encode the protein into token IDs.
    protein_tensor = model.base_model.encode(protein)
    token_ids = protein_tensor.sequence  # Tensor of token IDs
    
    # For many protein tokenizers the first and last tokens are special (BOS/EOS).
    # We assume each remaining token corresponds 1:1 with an amino acid.
    valid_positions = []
    original_tokens = []
    for pos in range(1, len(token_ids) - 1):
        token_id = int(token_ids[pos].item())
        token_str = model.base_model.tokenizer.decode([token_id]).strip()
        if token_str in aa_to_idx:
            valid_positions.append(pos)
            original_tokens.append(token_str)
    # If tokenization is truly 1:1, valid_positions will simply be [1, 2, ..., len(token_ids)-2].
    valid_positions_tensor = torch.tensor(valid_positions, device=device)
    
    # -------------------------------
    # 2. Mask all valid positions and get predictions
    # -------------------------------
    with torch.no_grad():
        # The model returns logits for each masked token position.
        masked_logits, _ = model(protein, mask_positions=valid_positions_tensor)
    
    # Instead of converting logits to probabilities via softmax,
    # we use log_softmax to obtain log likelihoods (LLR).
    llr = F.log_softmax(masked_logits, dim=-1)  # Shape: (n_masked_positions, vocab_size)
    
    # -------------------------------
    # 3. Extract log likelihoods for the standard 20 amino acids
    # -------------------------------
    # Ensure the amino acids are ordered consistently.
    std_aa_pairs = sorted(aa_to_idx.items(), key=lambda x: x[1])
    std_aas = [aa for aa, idx in std_aa_pairs]
    std_indices = [idx for aa, idx in std_aa_pairs]
    
    # Select only the columns corresponding to the standard amino acids.
    # llr_matrix will have shape (n_masked_positions, 20)
    llr_matrix = llr[:, std_indices].cpu().numpy()
    
    # -------------------------------
    # 4. Look up the log likelihood at the mutated residue position
    # -------------------------------
    # The mutated residue is assumed to be one-indexed (e.g. 394 means the 394th amino acid).
    mut_residue = row['mutated_residue']
    
    # Check that the mutated residue position is among our valid positions.
    # Because valid_positions are the token indices corresponding to the protein residues,
    # and assuming a 1:1 mapping, they should contain the mutated residue (if it is not a special token).
    if mut_residue in valid_positions:
        # Find its index in the list of valid positions.
        pos_idx = valid_positions.index(mut_residue)
        # Look up the amino acid at that position in the protein sequence.
        aa_at_pos = protein_seq[mut_residue - 1]  # Convert one-indexed to 0-indexed.
        if aa_at_pos in std_aas:
            aa_idx = std_aas.index(aa_at_pos)
            log_likelihood = llr_matrix[pos_idx, aa_idx]
        else:
            log_likelihood = None
    else:
        log_likelihood = None
    
    # -------------------------------
    # 5. Record the result for this variant
    # -------------------------------
    results.append({
        "protein": row["transcript"],
        "classification": row["clnsig"],
        "mutated_residue": mut_residue,
        "mutated_aa": protein_seq[mut_residue - 1] if mut_residue <= len(protein_seq) else None,
        "log_likelihood": log_likelihood  # This is your LLR for the mutated amino acid.
    })

# Create a DataFrame with the collected results.
result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
 data": {
  text/html": [
   <div>
   <style scoped>
       .dataframe tbody tr th:only-of-type {
           vertical-align: middle;
       }
   
       .dataframe tbody tr th {
           vertical-align: top;
       }
   
       .dataframe thead th {
           text-align: right;
       }
   </style>
   <table border="1" class="dataframe">
     <thead>
       <tr style="text-align: right;">
         <th></th>
         <th>protein</th>
         <th>classification</th>
         <th>mutated_residue</th>
         <th>mutated_aa</th>
         <th>probability</th>
       </tr>
     </thead>
     <tbody>
       <tr>
         <th>0</th>
         <td>NM_001385640.1</td>
         <td>(Benign,)</td>
         <td>394</td>
         <td>L</td>
         <td>0.351952</td>
       </tr>
       <tr>
         <th>1</th>
         <td>NM_001385641.1</td>
         <td>(Benign,)</td>
         <td>393</td>
         <td>L</td>
         <td>0.344486</td>
       </tr>
       <tr>
         <th>2</th>
         <td>NM_152486.4</td>
         <td>(Benign,)</td>
         <td>214</td>
         <td>L</td>
         <td>0.212726</td>
       </tr>
       <tr>
         <th>3</th>
         <td>NM_001385640.1</td>
         <td>(Pathogenic,)</td>
         <td>793</td>
         <td>E</td>
         <td>0.194827</td>
       </tr>
       <tr>
         <th>4</th>
         <td>NM_001385641.1</td>
         <td>(Pathogenic,)</td>
         <td>792</td>
         <td>E</td>
         <td>0.198134</td>
       </tr>
       <tr>
         <th>...</th>
         <td>...</td>
         <td>...</td>
         <td>...</td>
         <td>...</td>
         <td>...</td>
       </tr>
       <tr>
         <th>546</th>
         <td>XM_047422111.1</td>
         <td>(Benign,)</td>
         <td>41</td>
         <td>H</td>
         <td>0.056284</td>
       </tr>
       <tr>
         <th>547</th>
         <td>XM_047422112.1</td>
         <td>(Benign,)</td>
         <td>41</td>
         <td>H</td>
         <td>0.046137</td>
       </tr>
       <tr>
         <th>548</th>
         <td>NM_080605.4</td>
         <td>(Pathogenic,)</td>
         <td>0</td>
         <td>P</td>
         <td>NaN</td>
       </tr>
       <tr>
         <th>549</th>
         <td>NM_080605.4</td>
         <td>(Pathogenic,)</td>
         <td>5</td>
         <td>R</td>
         <td>0.409625</td>
       </tr>
       <tr>
         <th>550</th>
         <td>NM_080605.4</td>
         <td>(Benign,)</td>
         <td>36</td>
         <td>P</td>
         <td>0.194993</td>
       </tr>
     </tbody>
   </table>
   <p>551 rows × 5 columns</p>
   </div>"
      ],
  text/plain": [
               protein classification  mutated_residue mutated_aa  probability
   0    NM_001385640.1      (Benign,)              394          L     0.351952
   1    NM_001385641.1      (Benign,)              393          L     0.344486
   2       NM_152486.4      (Benign,)              214          L     0.212726
   3    NM_001385640.1  (Pathogenic,)              793          E     0.194827
   4    NM_001385641.1  (Pathogenic,)              792          E     0.198134
   ..              ...            ...              ...        ...          ...
   546  XM_047422111.1      (Benign,)               41          H     0.056284
   547  XM_047422112.1      (Benign,)               41          H     0.046137
   548     NM_080605.4  (Pathogenic,)                0          P          NaN
   549     NM_080605.4  (Pathogenic,)                5          R     0.409625
   550     NM_080605.4      (Benign,)               36          P     0.194993
   
   [551 rows x 5 columns]"
      ]
     },
 execution_count": 247,
 metadata": {},
 output_type": "execute_result"
    }
   ],
   "source": [
result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
result_df['classification'] = result_df['classification'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
result_df['classification'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
 data": {
  text/plain": [
   <Axes: xlabel='classification', ylabel='probability'>"
      ]
     },
 execution_count": 277,
 metadata": {},
 output_type": "execute_result"
    },
    {
 data": {
  image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANrZJREFUeJzt3XlclXX+//8noBxQARcEREEstdwXVMIyp4aiKU0nm8hM3MolSUemVMa9RrEaiXJUbjZumX40W3TKvmZSmCnmljW57zgpuIMrIOf6/eGPUydA4bAcvHzcbzduct7X+7qu18HbdXjyfl+Li2EYhgAAAEzC1dkFAAAAlCXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMBXCDQAAMJUqzi6golmtVp04cUJeXl5ycXFxdjkAAKAYDMPQxYsXFRgYKFfXm4/N3HHh5sSJEwoKCnJ2GQAAwAHHjx9XgwYNbtrnjgs3Xl5ekm78cLy9vZ1cDQAAKI6srCwFBQXZfo/fzB0XbvKnory9vQk3AADcZopzSgknFAMAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFNxarj59ttv1b17dwUGBsrFxUUrV6685TopKSlq3769LBaLGjdurIULF5Z7nQCAyiUnJ0crVqzQO++8oxUrVignJ8fZJaEScerjFy5fvqw2bdpo4MCBeuqpp27Z/8iRI3riiSc0dOhQLVmyRMnJyXrhhRdUr149RUZGVkDFAABnS0pK0ooVK5SXl2fX9pe//EVDhw51YmWoLJwabv70pz/pT3/6U7H7JyUlqVGjRpoxY4YkqVmzZvruu+/09ttvFxlusrOzlZ2dbXudlZVVuqJx20hLS9OgQYOUm5urqlWrat68eQoODnZ2WQBKISkpScuWLVOtWrU0aNAghYeHKzU1VfPmzdOyZcskiYCD2+ucm9TUVEVERNi1RUZGKjU1tch14uPj5ePjY/sKCgoq7zJRCTz88MOKjo5Wbm6uJCk3N1fR0dF6+OGHnVwZAEflT0XVqlVLK1asULdu3VSnTh1169bNrp0pKtxW4SY9PV3+/v52bf7+/srKytLVq1cLXScuLk6ZmZm2r+PHj1dEqXCihx9+WFartdBlVquVgAPcplatWqW8vDwNGjRIVarYTzxUqVJFAwcOVF5enlatWuWkClFZOHVaqiJYLBZZLBZnl4EKkpaWZgs2Li4uMgzDtiz/tdVqVVpaGlNUwG3mxIkTkqTw8PBCl+e35/fDneu2GrkJCAhQRkaGXVtGRoa8vb3l6enppKpQmQwYMMD2fVhYmGbNmqUvvvhCs2bNUlhYWKH9ANweAgMDJanIUxHy2/P74c51W4Wb8PBwJScn27V99dVXRaZ43Hnyr56oXbu2pk2bphYtWqhatWpq0aKFpk2bplq1atn1A3D76NGjh9zc3DRv3jxdv37dbtn169c1f/58ubm5qUePHk6qEJWFU8PNpUuXtHPnTu3cuVPSjUu9d+7cqbS0NEk3zpeJjo629R86dKgOHz6s0aNHa+/evZo9e7Y+/PBDjRo1yhnloxK7ePGiLly4oP79+6t79+7q37+/Lly4oEuXLjm7NAAOcnd311/+8hedP39ef/nLX/TZZ5/pzJkz+uyzz+za3d3dnV0qnMzF+O1JCRUsJSVFDz30UIH2fv36aeHCherfv7+OHj2qlJQUu3VGjRql3bt3q0GDBpowYYL69+9f7H1mZWXJx8dHmZmZ8vb2LoN3gcokLi7uplfP5QsPD1d8fHwFVASgrBV2nxs3Nzfuc2NyJfn97dRw4wyEG3PbunWrXn311Vv2e+utt9SxY8cKqAhAecjJydGqVat04sQJBQYGqkePHozYmFxJfn+b/mop3FlCQkLKtB+Ayil/igoozG11QjFwK8UZtSlJPwDA7YdwA1PJv1VA3bp15efnZ7fM399fdevWtesHADAfpqVgKlWrVtXVq1fl6empBQsW6KefftK5c+dUu3ZttW7d2nbyedWqVZ1bKACg3BBuYCqPPPKIPv74Y6Wlpenq1atq166dbdmlS5dsj9945JFHnFUiAKCcMS0FU+ncubPt+27dumnYsGHasmWLhg0bpm7duhXaDwBgLozcwFTatm2rmjVr6sKFC5KkPXv2aPTo0XZ9atasqbZt21Z8cQCACsHIDUzFzc1NsbGxkm48KPO38l/HxsbKzc2twmsDAFQMwg1M58EHH9Rrr71W6NVSr732mh588EEnVQYAqAjcoRimlZeXV+BqKUZsAOD2VJLf34zcwLTy8vJ08OBB/fzzzzp48CBPAgeAOwQnFMOUCnuwXlJSEg/WA4A7ACM3MJ2kpCQtW7ZMv59xNQxDy5YtU1JSkpMqAwBUBM65gank5OTosccek9VqVVhYmO677z5ZLBZlZ2dr8+bN+v777+Xq6qo1a9bwBGEAuI3wVHDcsT799FNZrVb5+/vryJEj+v77723L/Pz85O/vr4yMDH366aeKiopyYqUAgPLCtBRM5b///a+kGw/GPHXqlN2yU6dO2R6Ymd8PAGA+hBuYioeHh+37om7i9/t+AABzYVoKptKwYUPb9x07dlS/fv3UqFEjHTlyRIsWLdKWLVsK9AMAmAsjNzCVo0eP2r4/cOCADh8+rCtXrujw4cM6cOBAof0AAObCyA1MJf+cGkk6f/68ZsyYcct+AABzYeQGphIQECBJqlu3rurWrWu3zM/Pz9aW3w8AYD6M3MBUIiMjtW7dOp0+fVphYWF67rnnCtznJr8fAMCcCDcwlfbt26tatWq6cuWKtm7danefG1fXGwOV1apVU/v27Z1VIgCgnDEtBVNxc3PT2LFjJUlWq9VuWf7rsWPH8nRwADAxRm5QpGvXriktLc3ZZZRYQECAhg4dquXLl+v8+fO29tq1a+uZZ55RQECA9u/f78QKHRccHMw9egDgFgg3KFJaWpoGDx7s7DLKzLlz5277h2bOnTtXTZs2dXYZAFCpEW5QpODgYM2dO9fZZZTKsWPHNHXqVI0bN84UN+4LDg52dgkAUOkRblAkDw8P04wSNGzY0DTvBQBwc5xQDAAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMXp4WbWrFkKCQmRh4eHwsLCtGXLlpv2T0xM1D333CNPT08FBQVp1KhRunbtWgVVCwAAKjunhpvly5crNjZWkyZN0o4dO9SmTRtFRkbq1KlThfZfunSpxo4dq0mTJmnPnj2aN2+eli9frr///e8VXDkAAKisnBpuEhIS9OKLL2rAgAFq3ry5kpKSVK1aNc2fP7/Q/ps2bdL999+v5557TiEhIXr00UfVu3fvW472AACAO4fTwk1OTo62b9+uiIiIX4txdVVERIRSU1MLXadz587avn27LcwcPnxYX3zxhR5//PEi95Odna2srCy7LwAAYF5VnLXjM2fOKC8vT/7+/nbt/v7+2rt3b6HrPPfcczpz5oweeOABGYah69eva+jQoTedloqPj9eUKVPKtHYAAFB5Of2E4pJISUnRtGnTNHv2bO3YsUOffPKJVq9erddff73IdeLi4pSZmWn7On78eAVWDAAAKprTRm58fX3l5uamjIwMu/aMjAwFBAQUus6ECRPUt29fvfDCC5KkVq1a6fLlyxo8eLDGjRsnV9eCWc1ischisZT9GwAAAJWS00Zu3N3dFRoaquTkZFub1WpVcnKywsPDC13nypUrBQKMm5ubJMkwjPIrFgAA3DacNnIjSbGxserXr586dOigTp06KTExUZcvX9aAAQMkSdHR0apfv77i4+MlSd27d1dCQoLatWunsLAwHTx4UBMmTFD37t1tIQcAANzZnBpuoqKidPr0aU2cOFHp6elq27at1qxZYzvJOC0tzW6kZvz48XJxcdH48eP1yy+/qG7duurevbumTp3qrLcAAAAqGRfjDpvPycrKko+PjzIzM+Xt7e3sclDO9u/fr8GDB2vu3Llq2rSps8sBADioJL+/b6urpQAAAG6FcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEzFqfe5AQA4x7Vr15SWlubsMvAbwcHB8vDwcHYZpkC4AYA7UFpamgYPHuzsMvAb3I+r7BBuAOAOFBwcrLlz5zq7jFI5duyYpk6dqnHjxqlhw4bOLqfUgoODnV2CaRBuAOAO5OHhYZpRgoYNG5rmvaBscEIxAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFaeHm1mzZikkJEQeHh4KCwvTli1bbtr/woULGj58uOrVqyeLxaKmTZvqiy++qKBqAQBAZVfFmTtfvny5YmNjlZSUpLCwMCUmJioyMlL79u2Tn59fgf45OTl65JFH5Ofnp48++kj169fXsWPHVLNmzYovHgAAVEpODTcJCQl68cUXNWDAAElSUlKSVq9erfnz52vs2LEF+s+fP1/nzp3Tpk2bVLVqVUlSSEjITfeRnZ2t7Oxs2+usrKyyewMAAKDScdq0VE5OjrZv366IiIhfi3F1VUREhFJTUwtd5z//+Y/Cw8M1fPhw+fv7q2XLlpo2bZry8vKK3E98fLx8fHxsX0FBQWX+XgAAQOXhULi5fPlyqXd85swZ5eXlyd/f367d399f6enpha5z+PBhffTRR8rLy9MXX3yhCRMmaMaMGfrHP/5R5H7i4uKUmZlp+zp+/HipawcAAJWXQ9NS/v7+euaZZzRw4EA98MADZV1TkaxWq/z8/DR37ly5ubkpNDRUv/zyi9566y1NmjSp0HUsFossFkuF1QgAAJzLoZGbDz74QOfOndPDDz+spk2bavr06Tpx4kSJtuHr6ys3NzdlZGTYtWdkZCggIKDQderVq6emTZvKzc3N1tasWTOlp6crJyen5G8EAACYjkPhpmfPnlq5cqV++eUXDR06VEuXLlXDhg3VrVs3ffLJJ7p+/fott+Hu7q7Q0FAlJyfb2qxWq5KTkxUeHl7oOvfff78OHjwoq9Vqa9u/f7/q1asnd3d3R94KAAAwmVKdUFy3bl3Fxsbqp59+UkJCgtatW6enn35agYGBmjhxoq5cuXLT9WNjY/Xee+9p0aJF2rNnj4YNG6bLly/brp6Kjo5WXFycrf+wYcN07tw5jRw5Uvv379fq1as1bdo0DR8+vDRvAwAAmEipLgXPyMjQokWLtHDhQh07dkxPP/20Bg0apP/973964403tHnzZq1du7bI9aOionT69GlNnDhR6enpatu2rdasWWM7yTgtLU2urr/mr6CgIH355ZcaNWqUWrdurfr162vkyJEaM2ZMad4GAAAwEYfCzSeffKIFCxboyy+/VPPmzfXSSy/p+eeft7uZXufOndWsWbNbbismJkYxMTGFLktJSSnQFh4ers2bNztSNgAAuAM4FG4GDBigZ599Vhs3blTHjh0L7RMYGKhx48aVqjgAAICScijcnDx5UtWqVbtpH09PzyIvzwYAACgvDp1Q7OXlpVOnThVoP3v2rN1l2gAAABXNoXBjGEah7dnZ2VySDQAAnKpE01LvvvuuJMnFxUX//ve/VaNGDduyvLw8ffvtt7r33nvLtkIAAIASKFG4efvttyXdGLlJSkqym4Jyd3dXSEiIkpKSyrZCAACAEihRuDly5Igk6aGHHtInn3yiWrVqlUtRAAAAjnLoaqlvvvmmrOsAAAAoE8UON7GxsXr99ddVvXp1xcbG3rRvQkJCqQsDAABwRLHDzQ8//KDc3Fzb90VxcXEpfVUAAAAOKna4+e1UFNNSAACgsirVU8EBAAAqm2KP3Dz11FPF3ugnn3ziUDEAAAClVexw4+PjU551AAAAlIlih5sFCxaUZx0AAABlgnNuAACAqRR75KZ9+/ZKTk5WrVq11K5du5te8r1jx44yKQ4AAKCkih1uevToIYvFIknq2bNnedUDAABQKsUON5MmTSr0ewAAgMrEoWdL5du2bZv27NkjSWrevLlCQ0PLpCgAAABHORRu/ve//6l3797auHGjatasKUm6cOGCOnfurGXLlqlBgwZlWSMAAECxOXS11AsvvKDc3Fzt2bNH586d07lz57Rnzx5ZrVa98MILZV0jAABAsTk0crN+/Xpt2rRJ99xzj63tnnvu0cyZM9WlS5cyKw4AAKCkHBq5CQoKsj0h/Lfy8vIUGBhY6qIAAAAc5VC4eeutt/Tyyy9r27ZttrZt27Zp5MiR+uc//1lmxQEAAJRUsaelatWqZXfjvsuXLyssLExVqtzYxPXr11WlShUNHDiQ++AAAACnKXa4SUxMLMcyAAAAykaxw02/fv3Ksw4AAIAyUaqb+EnStWvXlJOTY9fm7e1d2s0CAAA4xKETii9fvqyYmBj5+fmpevXqqlWrlt0XAACAszgUbkaPHq2vv/5ac+bMkcVi0b///W9NmTJFgYGBev/998u6RgAAgGJzaFrqs88+0/vvv68//OEPGjBggLp06aLGjRurYcOGWrJkifr06VPWdQIAABSLQyM3586d01133SXpxvk1586dkyQ98MAD+vbbb8uuOgAAgBJyKNzcddddOnLkiCTp3nvv1YcffijpxohO/oM0AQAAnMGhcDNgwAD9+OOPkqSxY8dq1qxZ8vDw0KhRo/Tqq6+WaYEAAAAl4dA5N6NGjbJ9HxERoT179mjHjh1q3LixWrduXWbFAQAAlFSp73MjSSEhIQoJCSmLTQEAAJSKQ9NSkpScnKxu3brp7rvv1t13361u3bpp3bp1ZVkbAABAiTkUbmbPnq3HHntMXl5eGjlypEaOHClvb289/vjjmjVrVlnXCAAAUGwOTUtNmzZNb7/9tmJiYmxtI0aM0P33369p06Zp+PDhZVYgAABASTg0cnPhwgU99thjBdofffRRZWZmlrooAAAARzkUbp588kl9+umnBdpXrVqlbt26lbooAAAARxV7Wurdd9+1fd+8eXNNnTpVKSkpCg8PlyRt3rxZGzdu1N/+9reyrxIAAKCYih1u3n77bbvXtWrV0u7du7V7925bW82aNTV//nyNHz++7CoEAAAogWKHm/zHLQAAAFRmDt/nJp9hGDIMoyxqAQAAKDWHw83777+vVq1aydPTU56enmrdurUWL15clrUBAACUmEP3uUlISNCECRMUExOj+++/X5L03XffaejQoTpz5ozds6cAAAAqkkPhZubMmZozZ46io6NtbU8++aRatGihyZMnE24AAIDTODQtdfLkSXXu3LlAe+fOnXXy5MlSFwUAAOAoh8JN48aN9eGHHxZoX758uZo0aVLqogAAABzl0LTUlClTFBUVpW+//dZ2zs3GjRuVnJxcaOgBAACoKA6N3PTq1UtbtmyRr6+vVq5cqZUrV8rX11dbtmzRn//857KuEQAAoNhKPHKTm5urIUOGaMKECfrggw/KoyYAAACHlTjcVK1aVR9//LEmTJhQHvWYRkZGBk9IrwSOHTtm9y+cy8fHR/7+/s4uA4DJOXTOTc+ePbVy5Uou+S5CRkaGnu8brdycbGeXgv/f1KlTnV0CJFV1t+iDxe8TcACUK4fCTZMmTfTaa69p48aNCg0NVfXq1e2WjxgxokTbmzVrlt566y2lp6erTZs2mjlzpjp16nTL9ZYtW6bevXurR48eWrlyZYn2WZ4yMzOVm5Otq3d1ldXDx9nlAJWC67VM6fB6ZWZmEm4AlCuHws28efNUs2ZNbd++Xdu3b7db5uLiUqJws3z5csXGxiopKUlhYWFKTExUZGSk9u3bJz8/vyLXO3r0qF555RV16dLFkbdQIawePrJW93V2GQDKGNPOlQPTzpVLZZp2dijc/PYJ4fkPzXRxcXGogISEBL344osaMGCAJCkpKUmrV6/W/PnzNXbs2ELXycvLU58+fTRlyhRt2LBBFy5ccGjfAFBSTDtXPkw7Vw6VadrZoXAj3Ri9efvtt3XgwAFJN6aq/vrXv+qFF14o9jZycnK0fft2xcXF2dpcXV0VERGh1NTUItd77bXX5Ofnp0GDBmnDhg033Ud2drays3/9EMrKyip2fQDwe0w7AwVVtmlnh8LNxIkTlZCQoJdfflnh4eGSpNTUVI0aNUppaWl67bXXirWdM2fOKC8vr8APwt/fX3v37i10ne+++07z5s3Tzp07i7WP+Ph4TZkypVh9AaC4mHYGKi+Hws2cOXP03nvvqXfv3ra2J598Uq1bt9bLL79c7HBTUhcvXlTfvn313nvvyde3eB8qcXFxio2Ntb3OyspSUFBQudQHAACcz6Fwk5ubqw4dOhRoDw0N1fXr14u9HV9fX7m5uSkjI8OuPSMjQwEBAQX6Hzp0SEePHlX37t1tbVarVZJUpUoV7du3T3fffbfdOhaLRRaLpdg1AQCA25tDj1/o27ev5syZU6B97ty56tOnT7G34+7urtDQUCUnJ9varFarkpOTbdNdv3Xvvffqv//9r3bu3Gn7evLJJ/XQQw9p586djMgAAIDSnVC8du1a3XfffZKk77//XmlpaYqOjrabBkpISLjpdmJjY9WvXz916NBBnTp1UmJioi5fvmy7eio6Olr169dXfHy8PDw81LJlS7v1a9asKUkF2gEAwJ3JoXDz888/q3379pJuTBVJN6aYfH199fPPP9v6Fefy8KioKJ0+fVoTJ05Uenq62rZtqzVr1thOMk5LS5Orq0MDTAAA4A7kULj55ptvyrSImJgYxcTEFLosJSXlpusuXLiwTGsBAAC3N4ZEAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqVSKcDNr1iyFhITIw8NDYWFh2rJlS5F933vvPXXp0kW1atVSrVq1FBERcdP+AADgzuL0cLN8+XLFxsZq0qRJ2rFjh9q0aaPIyEidOnWq0P4pKSnq3bu3vvnmG6WmpiooKEiPPvqofvnllwquHAAAVEZVnF1AQkKCXnzxRQ0YMECSlJSUpNWrV2v+/PkaO3Zsgf5Lliyxe/3vf/9bH3/8sZKTkxUdHV0hNReX69ULzi4BqDQ4HgBUFKeGm5ycHG3fvl1xcXG2NldXV0VERCg1NbVY27hy5Ypyc3NVu3btQpdnZ2crOzvb9jorK6t0RZeA55FvK2xfAADgBqeGmzNnzigvL0/+/v527f7+/tq7d2+xtjFmzBgFBgYqIiKi0OXx8fGaMmVKqWt1xNVGD8rqWdMp+wYqG9erFwj8ACqE06elSmP69OlatmyZUlJS5OHhUWifuLg4xcbG2l5nZWUpKCioQuqzetaUtbpvhewLAADc4NRw4+vrKzc3N2VkZNi1Z2RkKCAg4Kbr/vOf/9T06dO1bt06tW7dush+FotFFoulTOoFAACVn1OvlnJ3d1doaKiSk5NtbVarVcnJyQoPDy9yvTfffFOvv/661qxZow4dOlREqQAA4Dbh9Gmp2NhY9evXTx06dFCnTp2UmJioy5cv266eio6OVv369RUfHy9JeuONNzRx4kQtXbpUISEhSk9PlyTVqFFDNWrUcNr7AAAAlYPTw01UVJROnz6tiRMnKj09XW3bttWaNWtsJxmnpaXJ1fXXAaY5c+YoJydHTz/9tN12Jk2apMmTJ1dk6QAAoBJyeriRpJiYGMXExBS6LCUlxe710aNHy78gAABw23L6HYoBAADKEuEGAACYSqWYlgKA2w2PkwB+VdmOB8INADiAuy0DlRfhBgAcwONVgF9VtserEG4AwAE8XgWovDihGAAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmEoVZxdgZq7XMp1dAlBpcDwAqCiEm3Lg4+Ojqu4W6fB6Z5cCVCpV3S3y8fFxdhkATI5wUw78/f31weL3lZnJX6rOduzYMU2dOlXjxo1Tw4YNnV3OHc/Hx0f+/v7OLgOAyRFuyom/vz8f4pVIw4YN1bRpU2eXAQCoAJxQDAAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIX73ACAA3icBPCrynY8EG4AoAR4vApQuMr0eBXCDQCUAI9XqTx4vErlUpker0K4AYAS4vEqlQuPV8HvcUIxAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwlUoRbmbNmqWQkBB5eHgoLCxMW7ZsuWn/FStW6N5775WHh4datWqlL774ooIqBQAAlZ3TH5y5fPlyxcbGKikpSWFhYUpMTFRkZKT27dsnPz+/Av03bdqk3r17Kz4+Xt26ddPSpUvVs2dP7dixQy1btnTCOwCA28+1a9eUlpbm7DJK5dixY3b/3u6Cg4Pl4eHh7DJMwcUwDMOZBYSFhaljx47617/+JUmyWq0KCgrSyy+/rLFjxxboHxUVpcuXL+vzzz+3td13331q27atkpKSCvTPzs5Wdna27XVWVpaCgoKUmZkpb2/vcnhH5mGWD7+pU6dq3LhxatiwobPLKTU+/FBW9u/fr8GDBzu7DPzG3Llzebr5TWRlZcnHx6dYv7+dOnKTk5Oj7du3Ky4uztbm6uqqiIgIpaamFrpOamqqYmNj7doiIyO1cuXKQvvHx8drypQpZVbznSQtLc00H35Tp051dgllgg8/lJXg4GDNnTvX2WXgN4KDg51dgmk4NdycOXNGeXl58vf3t2v39/fX3r17C10nPT290P7p6emF9o+Li7MLQ/kjN7g1PvwqHz78UFY8PDwIyjAtp59zU94sFossFouzy7gt8eEHALgdOfVqKV9fX7m5uSkjI8OuPSMjQwEBAYWuExAQUKL+AADgzuLUcOPu7q7Q0FAlJyfb2qxWq5KTkxUeHl7oOuHh4Xb9Jemrr74qsj8AALizOH1aKjY2Vv369VOHDh3UqVMnJSYm6vLlyxowYIAkKTo6WvXr11d8fLwkaeTIkeratatmzJihJ554QsuWLdO2bds4NwQAAEiqBOEmKipKp0+f1sSJE5Wenq62bdtqzZo1tpOG09LS5Or66wBT586dtXTpUo0fP15///vf1aRJE61cuZJ73AAAAEmV4D43Fa0k18kDAIDKoSS/vyvF4xcAAADKCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYitPvUFzR8u9ZmJWV5eRKAABAceX/3i7OvYfvuHBz8eJFSVJQUJCTKwEAACV18eJF+fj43LTPHff4BavVqhMnTsjLy0suLi7OLgflLCsrS0FBQTp+/DiP2wBMhuP7zmIYhi5evKjAwEC7Z04W5o4buXF1dVWDBg2cXQYqmLe3Nx9+gElxfN85bjVik48TigEAgKkQbgAAgKkQbmBqFotFkyZNksVicXYpAMoYxzeKcsedUAwAAMyNkRsAAGAqhBsAAGAqhBsAAGAqhBuUq7Nnz8rPz09Hjx51ah2TJ09W27ZtK3y/zz77rGbMmFHh+wVKwhnHqbOOSUccPXpULi4u2rlzZ5lsb82aNWrbtq2sVmuZbA8FEW5QrqZOnaoePXooJCTE9gGRLyUlRS4uLrYvT09PtWjRQnPnzi3zOl555RUlJyeX+XZDQkKUkpJS5PLx48dr6tSpyszMLPN9A2WlJMepv7+/evXqpcOHDxd7+y4uLlq5cmU5VF4xgoKCdPLkSbVs2bJY/SdPnqz+/fsXufyxxx5T1apVtWTJkjKqEL9HuEG5uXLliubNm6dBgwbdtN++fft08uRJ7d69W0OGDNGwYcPKPIjUqFFDderUKdNtFkfLli11991364MPPqjwfQPFUZLj9MSJE1qxYoV27dql7t27Ky8vr4KqdC43NzcFBASoSpWyu6l///799e6775bZ9mCPcINy88UXX8hisei+++67aT8/Pz8FBASoUaNGGjFihBo1aqQdO3bYllutVsXHx6tRo0by9PRUmzZt9NFHH9mW5/9lmZycrA4dOqhatWrq3Lmz9u3bZ+vz+yHw69eva8SIEapZs6bq1KmjMWPGqF+/furZs6etzx/+8AeNGDFCo0ePVu3atRUQEKDJkyeX+OfQvXt3LVu2rMTrARWhJMdpvXr19OCDD2rixInavXu3Dh48qK1bt+qRRx6Rr6+vfHx81LVrV7vjNyQkRJL05z//WS4uLrbX+RYvXqyQkBD5+Pjo2WeftT3cWJKys7M1YsQI+fn5ycPDQw888IC2bt1qt/5//vMfNWnSRB4eHnrooYe0aNEiubi46MKFC7Y+3333nbp06SJPT08FBQVpxIgRunz5sl2N06ZN08CBA+Xl5aXg4GC7EeTCpqV27dqlbt26ydvbW15eXurSpYsOHTp0qx+3Tffu3bVt27YSrYPiI9yg3GzYsEGhoaHF7m8YhtasWaO0tDSFhYXZ2uPj4/X+++8rKSlJu3bt0qhRo/T8889r/fr1duuPGzdOM2bM0LZt21SlShUNHDiwyH298cYbWrJkiRYsWKCNGzcqKyur0GHzRYsWqXr16vr+++/15ptv6rXXXtNXX31V7PckSZ06ddKWLVuUnZ1dovWAilDS41SSPD09JUk5OTm6ePGi+vXrp++++06bN29WkyZN9Pjjj9tCSn4YWbBggU6ePGkXTg4dOqSVK1fq888/1+eff67169dr+vTptuWjR4/Wxx9/rEWLFmnHjh1q3LixIiMjde7cOUnSkSNH9PTTT6tnz5768ccfNWTIEI0bN86u1kOHDumxxx5Tr1699NNPP2n58uX67rvvFBMTY9dvxowZ6tChg3744Qe99NJLGjZsmN0fSL/1yy+/6MEHH5TFYtHXX3+t7du3a+DAgbp+/Xqxf4bBwcHy9/fXhg0bir0OSsAAykmPHj2MgQMHFrn8m2++MSQZ1atXN6pXr25UqVLFcHV1Nf7xj3/Y+ly7ds2oVq2asWnTJrt1Bw0aZPTu3dtuO+vWrbMtX716tSHJuHr1qmEYhjFp0iSjTZs2tuX+/v7GW2+9ZXt9/fp1Izg42OjRo4etrWvXrsYDDzxgt9+OHTsaY8aMKf4PwTCMH3/80ZBkHD16tETrARWhuMfp+fPnDcMwjBMnThidO3c26tevb2RnZxfon5eXZ3h5eRmfffaZrU2S8emnn9r1mzRpklGtWjUjKyvL1vbqq68aYWFhhmEYxqVLl4yqVasaS5YssS3PyckxAgMDjTfffNMwDMMYM2aM0bJlS7vtjhs3zq7eQYMGGYMHD7brs2HDBsPV1dX2+dCwYUPj+eefty23Wq2Gn5+fMWfOHMMwDOPIkSOGJOOHH34wDMMw4uLijEaNGhk5OTlF/tyKo127dsbkyZNLtQ0U7o57KjgqztWrV+Xh4XHLfhs2bJCXl5eys7O1ZcsWxcTEqHbt2ho2bJgOHjyoK1eu6JFHHrFbJycnR+3atbNra926te37evXqSZJOnTql4OBgu36ZmZnKyMhQp06dbG1ubm4KDQ0tcPXCb7eZv91Tp07d8j39Vv5fuVeuXCnRekBFKO5x2qBBAxmGoStXrqhNmzb6+OOP5e7uroyMDI0fP14pKSk6deqU8vLydOXKFaWlpd1ymyEhIfLy8rK9/u3xdejQIeXm5ur++++3La9atao6deqkPXv2SLpxHlDHjh3ttvnb41qSfvzxR/300092J+8ahiGr1aojR46oWbNmkuyPdRcXFwUEBBR5rO/cuVNdunRR1apVb/keb8bT05PPhXJCuEG58fX11fnz52/Zr1GjRqpZs6YkqUWLFvr+++81depUDRs2TJcuXZIkrV69WvXr17db7/fPk/ntB03+1R6lvdTy9x9eLi4uJd5m/hB63bp1S1ULUB6Ke5xu2LBB3t7e8vPzswsk/fr109mzZ/XOO++oYcOGslgsCg8PV05Ozi23WRbH161cunRJQ4YM0YgRIwos++0fPiWpJf8PltI6d+4cnwvlhHNuUG7atWun3bt3l3g9Nzc3Xb16VZLUvHlzWSwWpaWlqXHjxnZfQUFBDtXl4+Mjf39/u7n/vLw8u5Mgy9LPP/+sBg0ayNfXt1y2D5RGcY/TRo0a6e6777YLNpK0ceNGjRgxQo8//rhatGghi8WiM2fO2PWpWrVqia+suvvuu+Xu7q6NGzfa2nJzc7V161Y1b95cknTPPfdo27Ztduv9/oTj9u3ba/fu3QU+Pxo3bix3d/cS1ZSvdevW2rBhg3Jzcx1aX5KuXbumQ4cOFRiBRtkg3KDcREZGateuXbf8q/DUqVNKT0/XsWPHtGLFCi1evFg9evSQJHl5eemVV17RqFGjtGjRIh06dEg7duzQzJkztWjRIodre/nllxUfH69Vq1Zp3759GjlypM6fP293f4+ysmHDBj366KNlvl2gLBT3OC1KkyZNtHjxYu3Zs0fff/+9+vTpU2BkIyQkRMnJyUpPTy/2fqpXr65hw4bp1Vdf1Zo1a7R79269+OKLunLliu2y9SFDhmjv3r0aM2aM9u/frw8//FALFy6U9Ovo7ZgxY7Rp0ybFxMRo586dOnDggFatWlXghOKSiImJUVZWlp599llt27ZNBw4c0OLFi4s8Abkwmzdvto1yoewRblBuWrVqpfbt2+vDDz+8ab977rlH9erVU+PGjTVmzBgNGTJEM2fOtC1//fXXNWHCBMXHx6tZs2Z67LHHtHr1ajVq1Mjh2saMGaPevXsrOjpa4eHhqlGjhiIjI4t17sHN/OEPf7C7ede1a9e0cuVKvfjii6XaLlBeinucFmXevHk6f/682rdvr759+9ou3f6tGTNm6KuvvlJQUFCJRiqmT5+uXr16qW/fvmrfvr0OHjyoL7/8UrVq1ZJ0YzTpo48+0ieffKLWrVtrzpw5tqul8qetW7durfXr12v//v3q0qWL2rVrp4kTJyowMNCh9ytJderU0ddff61Lly6pa9euCg0N1XvvvVfkOTgLFy4s8IfT//3f/6lPnz6qVq2aw3XgJpx9RjPM7fPPPzeaNWtm5OXlObuUm8rLyzOaNm1qjB8/vlTbCQ4ONhYsWGB7PXv2bOORRx4pZXVA+bpdjtPi+Mc//mE0aNDA2WXYmThxotG1a1fb69OnTxu1a9c2Dh8+7LyiTI4TilGunnjiCR04cEC//PKLw+fIlIdjx45p7dq16tq1q7Kzs/Wvf/1LR44c0XPPPefwNnft2iUfHx9FR0fb2qpWrWo3CgVURpX1OC2O2bNnq2PHjqpTp442btyot956q1RTTuXh//2//6d//etfttdHjx7V7NmzSzX6jJtzMQzDcHYRQEU7fvy4nn32Wf38888yDEMtW7bU9OnT9eCDDzq7NAAlMGrUKC1fvlznzp1TcHCw+vbtq7i4uDJ9VAJuP4QbAABgKpxQDAAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwA8BhR48elYuLi3bu3Fnu+1q4cKHtAav55s6dq6CgILm6uioxMVGTJ09W27Zty72WkJAQJSYmlvt+ADiGS8EBOOzo0aNq1KiRfvjhh3IPFVevXtXFixdtt/bPysqSr6+vEhIS1KtXL/n4+MhqtSo7O1t16tQpk30uXLhQf/3rX3XhwgW79tOnT6t69ercOh+opLjLEYDbgqenp90DGdPS0pSbm6snnnhC9erVs7XXqFGj3GupW7duue8DgOOYlgJwS1arVW+++aYaN24si8Wi4OBgTZ06tUC/vLw8DRo0SI0aNZKnp6fuuecevfPOO3Z9UlJS1KlTJ1WvXl01a9bU/fffr2PHjkmSfvzxRz300EPy8vKSt7e3QkNDtW3bNkn201ILFy5Uq1atJEl33XWXXFxcdPTo0UKnpebPn68WLVrIYrGoXr16drfmT0hIUKtWrVS9enUFBQXppZde0qVLl2x1DhgwQJmZmXJxcZGLi4smT54sqeC0VFpamnr06KEaNWrI29tbzzzzjDIyMmzL8+tavHixQkJC5OPjo2effVYXL14s+X8GgFsi3AC4pbi4OE2fPl0TJkzQ7t27tXTpUvn7+xfoZ7Va1aBBA61YsUK7d+/WxIkT9fe//932xOnr16+rZ8+e6tq1q3766SelpqZq8ODBticm9+nTRw0aNNDWrVu1fft2jR07ttAnLUdFRWndunWSpC1btujkyZOFPhNpzpw5Gj58uAYPHqz//ve/+s9//qPGjRvblru6uurdd9/Vrl27tGjRIn399dcaPXq0JKlz585KTEyUt7e3Tp48qZMnT+qVV14p9D336NFD586d0/r16/XVV1/p8OHDioqKsut36NAhrVy5Up9//rk+//xzrV+/XtOnTy/ufwGAknDiQzsB3AaysrIMi8VivPfeewWWHTlyxJBk/PDDD0WuP3z4cKNXr16GYRjG2bNnDUlGSkpKoX29vLyMhQsXFrpswYIFho+Pj+31Dz/8YEgyjhw5YmubNGmS0aZNG9vrwMBAY9y4cUW/ud9ZsWKFUadOnSL3ma9hw4bG22+/bRiGYaxdu9Zwc3Mz0tLSbMt37dplSDK2bNliq6tatWpGVlaWrc+rr75qhIWFFbs2AMXHyA2Am9qzZ4+ys7P1xz/+sVj9Z82apdDQUNWtW1c1atTQ3LlzlZaWJkmqXbu2+vfvr8jISHXv3l3vvPOOTp48aVs3NjZWL7zwgiIiIjR9+nQdOnTI4bpPnTqlEydO3LTudevW6Y9//KPq168vLy8v9e3bV2fPntWVK1eKvZ89e/YoKCjIbuSoefPmqlmzpvbs2WNrCwkJkZeXl+11vXr1dOrUqRK+KwDFQbgBcFO/PYn3VpYtW6ZXXnlFgwYN0tq1a7Vz504NGDBAOTk5tj4LFixQamqqOnfurOXLl6tp06bavHmzpBvnpuzatUtPPPGEvv76azVv3lyffvppudR99OhRdevWTa1bt9bHH3+s7du3a9asWZJkV29Z+f30mouLi6xWa5nvBwDhBsAtNGnSRJ6enkpOTr5l340bN6pz58566aWX1K5dOzVu3LjQ0Zd27dopLi5OmzZtUsuWLbV06VLbsqZNm2rUqFFau3atnnrqKS1YsMChur28vBQSElJk3du3b5fVatWMGTN03333qWnTpjpx4oRdH3d3d+Xl5d10P82aNdPx48d1/PhxW9vu3bt14cIFNW/e3KHaAZQO4QbATXl4eGjMmDEaPXq03n//fR06dEibN2/WvHnzCvRt0qSJtm3bpi+//FL79+/XhAkTtHXrVtvyI0eOKC4uTqmpqTp27JjWrl2rAwcOqFmzZrp69apiYmKUkpKiY8eOaePGjdq6dauaNWvmcO2TJ0/WjBkz9O677+rAgQPasWOHZs6cKUlq3LixcnNzNXPmTB0+fFiLFy9WUlKS3fohISG6dOmSkpOTdebMmUKnqyIiItSqVSv16dNHO3bs0JYtWxQdHa2uXbuqQ4cODtcOwHGEGwC3NGHCBP3tb3/TxIkT1axZM0VFRRV6vsiQIUP01FNPKSoqSmFhYTp79qxeeukl2/Jq1app79696tWrl5o2barBgwdr+PDhGjJkiNzc3HT27FlFR0eradOmeuaZZ/SnP/1JU6ZMcbjufv36KTExUbNnz1aLFi3UrVs3HThwQJLUpk0bJSQk6I033lDLli21ZMkSxcfH263fuXNnDR06VFFRUapbt67efPPNAvtwcXHRqlWrVKtWLT344IOKiIjQXXfdpeXLlztcN4DS4Q7FAADAVBi5AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApvL/ATsgN/Q+0o0uAAAAAElFTkSuQmCC",
  text/plain": [
   <Figure size 640x480 with 1 Axes>"
      ]
     },
 metadata": {},
 output_type": "display_data"
    }
   ],
   "source": [
sns.boxplot(x='classification', y='probability', data=result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
# Map from common numeric/letter chromosome IDs (as found in VCF) 
# to the full NCBI contig names in the FASTA
chrom_map = {
    "1":  "NC_000001.11",
    "2":  "NC_000002.12",
    "3":  "NC_000003.12",
    "4":  "NC_000004.12",
    "5":  "NC_000005.10",
    "6":  "NC_000006.12",
    "7":  "NC_000007.14",
    "8":  "NC_000008.11",
    "9":  "NC_000009.12",
    "10": "NC_000010.11",
    "11": "NC_000011.10",
    "12": "NC_000012.12",
    "13": "NC_000013.11",
    "14": "NC_000014.9",
    "15": "NC_000015.10",
    "16": "NC_000016.10",
    "17": "NC_000017.11",
    "18": "NC_000018.10",
    "19": "NC_000019.10",
    "20": "NC_000020.11",
    "21": "NC_000021.9",
    "22": "NC_000022.11",
    "X":  "NC_000023.11",
    "Y":  "NC_000024.10",
    "MT": "NC_012920.1",  # Mitochondrial DNA
}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
 name": "stderr",
 output_type": "stream",
 text": [
  /clusterfs/nilah/sergio/miniconda3/envs/ESM_cambrian/lib/python3.10/site-packages/Bio/Seq.py:2879: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.
    warnings.warn(\n"
     ]
    }
   ],
   "source": [
def get_clnsig_string(variant):
    """
    Returns the ClinVar clinical significance (CLNSIG)
    e.g. 'Pathogenic', 'Benign', 'Likely_pathogenic', etc.
    """
    return variant.INFO.get("CLNSIG", None)

# ---------------------------
# 4) Helper to check if variant is "coding"
#    We'll check the 'MC' (Molecular Consequence) field
#    or a 'CSQ' field if your VCF is annotated by VEP.
#
#    In standard ClinVar VCF releases, 'MC' might look like:
#    MC=SO:0001583|missense_variant
#
#    We'll do a naive search for known terms: "missense_variant",
#    "nonsense_variant", "synonymous_variant", etc.
# ---------------------------
def is_coding_variant(variant):
    # Attempt to get 'MC'. If not present, try 'CSQ' or skip.
    mc = variant.INFO.get("MC", "")
    # If your file is annotated with VEP's 'CSQ', you'd parse differently:
    # csq = variant.INFO.get("CSQ", "")
    # ...
    
    # Search for known coding terms in 'MC'
    coding_terms = [
        "missense_variant",
        "nonsense_variant",
        "synonymous_variant",
        "frameshift_variant",
        "inframe_deletion",
        "inframe_insertion",
        # add others if you wish, e.g. "stop_lost", "start_lost", etc.
    ]
    return any(term in mc for term in coding_terms)

# ---------------------------
# 5) Filter for (A) coding, and (B) benign or pathogenic
# ---------------------------
vcf = cyvcf2.VCF(vcf_path)

coding_benign_path = []
for variant in vcf:
    clnsig = get_clnsig_string(variant)
    if clnsig is None:
        continue
    clnsig_lower = clnsig.lower()
    
    if ("benign" in clnsig_lower or "pathogenic" in clnsig_lower) and is_coding_variant(variant):
        coding_benign_path.append(variant)

# ---------------------------
# 6) Randomly pick 100 of them
# ---------------------------
num_to_select = 100
if len(coding_benign_path) < num_to_select:
    raise ValueError(f"Found only {len(coding_benign_path)} coding benign/pathogenic variants, need 100!")
selected_vars = random.sample(coding_benign_path, num_to_select)

# ---------------------------
# 7) Open reference FASTA
# ---------------------------
reference = pysam.FastaFile(fasta_path)

# ---------------------------
# 8) Build DataFrame
# ---------------------------
rows = []
flank = 1000  # how much around the variant to fetch, purely example

for var in selected_vars:
    chrom = var.CHROM
    pos   = var.POS       # 1-based
    ref   = var.REF
    alts  = var.ALT
    clnsig = get_clnsig_string(var)
    
    if not alts:
        continue
    alt = alts[0]

    chrom_mapped = chrom_map.get(chrom, chrom)

    start = pos - 1 - flank
    end   = pos - 1 + flank + len(ref)
    if start < 0:
        start = 0

    # Fetch ref seq from FASTA
    try:
        ref_seq = reference.fetch(chrom_mapped, start, end)
    except KeyError:
        # If the chrom doesn't exist in FASTA
        continue

    # Build naive mutated seq
    offset_in_snippet = flank
    mutated_seq = (
        ref_seq[:offset_in_snippet] +
        alt +
        ref_seq[offset_in_snippet + len(ref):]
    )

    # Translate naive snippet ignoring real frames, exons, or strand
    ref_protein = str(Seq(ref_seq).translate(to_stop=False))
    mut_protein = str(Seq(mutated_seq).translate(to_stop=False))

    rows.append({
        "chrom": chrom,
        "pos": pos,
        "ref_allele": ref,
        "alt_allele": alt,
        "clnsig": clnsig,
        "ref_protein_seq": ref_protein,
        "mut_protein_seq": mut_protein,
    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
 name": "stdout",
 output_type": "stream",
 text": [
    chrom        pos ref_allele alt_allele                        clnsig  \\
  0    MT       8842          A          C                 Likely_benign   
  1    17   27760137          G          T                 Likely_benign   
  2     2   32136638          G          T             Likely_pathogenic   
  3     7   43623585          T          C                        Benign   
  4     7     729784          C          T                        Benign   
  5    17   31259040          G          C  Pathogenic/Likely_pathogenic   
  6     9   95449850          T          C                 Likely_benign   
  7     1   55039960          G          C                 Likely_benign   
  8     2   96293090          C          T                    Pathogenic   
  9     X  133661825          C          T                        Benign   
  
                                       ref_protein_seq  \\
  0  *QTRSTIPPLPSNQLATNGTEPTSTPTTAD*SSTPTYFPHYS*NQA...   
  1  ACWPQGGGERGTKG*GVSPLPARTLQGARLRMRCMDAPGARLGLER...   
  2  SGLSGNILIFIGWARWLMPVIPAPREAKLGGSLEVRSLRSAWPTKL...   
  3  *IFLRSIFIIFFLNPCIFDSVFLLCLCVAAIYFISKFFVFVFFFVR...   
  4  AWSIPSSPAPLAFLSPGWGASPLVSVTLGNGREVEALTQSLTGIAV...   
  5  SNMQYK**YSEDLFSGFFYPSHP*GFSFL*DTLIVL*YDIRLELRG...   
  6  YPL*DQTTGRWHLYS*ERVKYWLFPMI*PSLYLISASHLPV*CAAQ...   
  7  ECTYMTSLQT*NLNLCSINPLKCM*AGHQKQAISSRSS*LVRSVCR...   
  8  KFTVLELRN*TNFNILS*TATLNRLQLQIRASQLRIYVQAPNKSQS...   
  9  **ILNRILCSHDK*LI*RFVGTRHGGSHL*S*HFAGLMQEDCLSPG...   
  
                                       mut_protein_seq  
  0  *QTRSTIPPLPSNQLATNGTEPTSTPTTAD*SSTPTYFPHYS*NQA...  
  1  ACWPQGGGERGTKG*GVSPLPARTLQGARLRMRCMDAPGARLGLER...  
  2  SGLSGNILIFIGWARWLMPVIPAPREAKLGGSLEVRSLRSAWPTKL...  
  3  *IFLRSIFIIFFLNPCIFDSVFLLCLCVAAIYFISKFFVFVFFFVR...  
  4  AWSIPSSPAPLAFLSPGWGASPLVSVTLGNGREVEALTQSLTGIAV...  
  5  SNMQYK**YSEDLFSGF